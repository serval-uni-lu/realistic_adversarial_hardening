import os
import json
import shutil
import hashlib
import pandas as pd


def make_dir(dir_path):
    if dir_path != '' and not os.path.exists(dir_path):
        try:
            os.makedirs(dir_path)
        except Exception as e:
            print(e)

'''
utilities in the form of small functions.
'''

def write_json(filepath, data):
    '''
    Convenience method for writing to a json
    :param filepath: string of the filename
    :param data: Data to be written as json
    '''
    with open(filepath, 'w') as f:
        json.dump(data, f)


def read_json(filepath):
    '''
    Convenience method for reading from a json
    :param filepath: string of the filename
    :return: Data read from json
    '''
    if os.path.isfile(filepath):
        with open(filepath) as f:
            return json.load(f)
    else:
        return None


def compute_sha1(filepath):
    sha1sum = hashlib.sha1()
    with open(filepath, 'rb') as source:
        block = source.read(2 ** 16)
        while len(block) != 0:
            sha1sum.update(block)
            block = source.read(2 ** 16)
    return sha1sum.hexdigest()


def load_wild_df(light=False):
    cur_dir = os.path.dirname(os.path.abspath(__file__))
    df_path = '../data/wild.pickle'
    df_path = os.path.abspath(os.path.join(cur_dir, df_path))

    if os.path.exists(df_path):
        df = pd.read_pickle(df_path)
        if light:
            labels = [l for l in LABELS if l in df.columns]
            df = df[labels]
        return df
    else:
        return None


def save_wild_df(df):
    cur_dir = os.path.dirname(os.path.abspath(__file__))
    df_path = '../data/wild.pickle'
    df_path = os.path.abspath(os.path.join(cur_dir, df_path))
    df.to_pickle(df_path)


