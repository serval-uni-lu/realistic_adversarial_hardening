import os
import glob
import pandas as pd
import sys
import numpy as np
# append the path of the parent directory
sys.path.append("..")

def get_predictions(model, test_X, threshold):
    predicted_proba = model.predict_proba(test_X)
    predictions = (predicted_proba[:,1] >= threshold).astype('int')
    return predictions


def join_dfs(directory, out_file):
    os.chdir(directory)
    extension = 'csv'
    all_filenames = [i for i in glob.glob('*.{}'.format(extension))]
    print(all_filenames)
    #combine all files in the list
    combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])
    #export to csv
    combined_csv.to_csv( out_file, index=False)
    print(combined_csv.shape)

def get_success_metrics(info_df):
    print("Generated functional samples ", info_df.shape)
    info_df_wod = info_df.drop_duplicates()
    unique = info_df['original_sample_sha1'].unique().shape[0]
    unique_samples = info_df['original_sample_sha1'].unique()
    #unique_500 = np.random.choice(unique_samples, size=500, replace=False)
    info_df = info_df[info_df['original_sample_sha1'].isin(list(unique_samples))]
    print("Unique processed samples", unique)
    succ  = info_df[info_df['score']<0.9]
    succ  = succ.drop_duplicates(['modified_sample_path', 'original_sample_sha1']).groupby('original_sample_sha1').head(1)
    succ_shas = succ['original_sample_sha1'].to_numpy()
    print("Successful samples with at min 1", succ.shape)
    succ_rate = succ.shape[0]/info_df.shape[0]
    print("Success rate", succ_rate*100)
    succ_r = (succ.shape[0]/unique)*100
    print("Unique success samples", unique)
    print("Success rate real",succ_r )
    return succ_shas

def get_leftovers(info_df, adversarial_paths, adversarial_idx, leftover_idx_path):
    info = pd.read_csv(info_df)
    paths = pd.read_csv(adversarial_paths)
    adversarial_idx = np.load(adversarial_idx)
    paths_adv = paths.iloc[adversarial_idx]
    print("Generated functional samples", info.shape)
    #riginal_shas = info['original_sample_sha1'].unique().tolist()
    original_shas = info['original_sample_sha1'].unique()
    print("Unique original files",  original_shas.shape)
    all_rest = paths_adv[paths_adv.sha1.isin(original_shas.tolist())]
    missing_sha = paths_adv[~paths_adv.sha1.isin(original_shas.tolist())]
    missing_idx = missing_sha.index.to_numpy()
    print("Missing files", missing_idx.shape)
    np.save(leftover_idx_path, missing_idx)

