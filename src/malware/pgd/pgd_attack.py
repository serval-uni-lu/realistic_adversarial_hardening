import os
os.environ['PYTHONHASHSEED']=str(5)
import time
from datetime import datetime
import pickle
import joblib
import numpy as np
import random as rn
import tensorflow as tf

from tensorflow.keras.utils import to_categorical
from keras.models import load_model
from art.attacks.evasion import ProjectedGradientDescent as PGD
from art.classifiers import KerasClassifier as kc
from helpers import get_mutability_mask, save_predictions, load_data_pgd_attack
import warnings
warnings.filterwarnings("ignore", category = FutureWarning)
tf.compat.v1.disable_eager_execution()
rn.seed(5)
np.random.seed(5)


if __name__ == '__main__':

    ## Replace here the size of the training set
    size = 1500
    model_path = "../data/models/neural_networks/nn_model_clean.h5"
    adv_cand_path = f"../data/adversarial_candidates/training/candidates/adversarial_cand_nn_{size}.npy"
    pred_train_path =   f"pred_train/nn/nn_pred_train_{size}.npy"

    nn, malware_adv, scaler, y_pred = load_data_pgd_attack(size, model_path, adv_cand_path, pred_train_path)
    ## Generate adversarial
    adv_label = 1 - y_pred
    mask = get_mutability_mask()
    kc_classifier = kc(nn, clip_values=(0,1))

    pgd = PGD(kc_classifier, eps = 0.1, targeted=True, verbose=False, max_iter=1, norm=2)
    start_time = datetime.now()
    attacks = pgd.generate(x=malware_adv, y=adv_label, mask=mask)
    end_time = datetime.now()
    print('Duration: {}'.format(end_time - start_time))

    original_unscaled = scaler.inverse_transform(attacks)
    np.save(f"adversarial/nn/scaled/pgd_adv_scaled.npy", attacks)
    np.save(f"adversarial/nn/unscaled/pgd_adv_unscaled.npy", original_unscaled)
